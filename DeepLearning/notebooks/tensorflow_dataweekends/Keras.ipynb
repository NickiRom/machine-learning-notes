{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "### Pros\n",
    "- simple framework, high-level\n",
    "\n",
    "### Cons\n",
    "- doesn't scale well, has some GPU support but you're better off using tensorflow\n",
    "- can't scale to multiple machines\n",
    "\n",
    "### Callbacks\n",
    "\n",
    "A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training.\n",
    "\n",
    "#### ProgbarLogger\n",
    "Callback that prints metrics to stdout.\n",
    "\n",
    "        keras.callbacks.ProgbarLogger(count_mode='samples', stateful_metrics=None)\n",
    "\n",
    "#### ModelCheckpoint\n",
    "Save the model after every epoch.\n",
    "\n",
    "        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "#### EarlyStopping\n",
    "Stop training when a monitored quantity has stopped improving.\n",
    "\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "\n",
    "#### LearningRateScheduler\n",
    "Learning rate scheduler.\n",
    "\n",
    "        keras.callbacks.LearningRateScheduler(schedule, verbose=0)\n",
    "\n",
    "#### TensorBoard\n",
    "TensorBoard basic visualizations.\n",
    "\n",
    "        keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "#### ReduceLROnPlateau\n",
    "Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n",
    "\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "#### CSVLogger\n",
    "Callback that streams epoch results to a csv file.\n",
    "\n",
    "Supports all values that can be represented as a string, including 1D iterables such as np.ndarray.\n",
    "\n",
    "        keras.callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "\n",
    "#### Load images in batches\n",
    "- image_generator\n",
    "- or model.fit_generator\n",
    "- or convert model to estimator first and use tf dataset API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained models\n",
    "- in keras.applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed computing in Keras\n",
    "\n",
    "https://keras.io/why-use-keras/#keras-has-strong-multi-gpu-support-and-distributed-training-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
